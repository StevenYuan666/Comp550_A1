{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "np.random.seed(550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load two data set, and label positive case as one and negative case as zero\n",
    "data_positive = np.loadtxt(\"rt-polarity.pos\", dtype='str', delimiter='\\n', encoding='latin-1')\n",
    "# print(data_positive)\n",
    "ones = np.ones(data_positive.shape[0], int)\n",
    "data_positive = np.c_[data_positive, ones]\n",
    "data_negative = np.loadtxt(\"rt-polarity.neg\", dtype='str', delimiter='\\n', encoding='latin-1')\n",
    "zeros = np.zeros(data_negative.shape[0], int)\n",
    "data_negative = np.c_[data_negative, zeros]\n",
    "# Concatenate two data frame\n",
    "data = np.r_[data_positive, data_negative]\n",
    "# Randomly shuffle the whole dataset\n",
    "np.random.shuffle(data)\n",
    "# Split to training and test set\n",
    "training_set, test_set = train_test_split(data, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define a general experiment procedure\n",
    "def experiment(train_X, train_Y, test_X, test_Y, n_splits=5):\n",
    "    # Use 5 cross validation by default\n",
    "    kf = KFold(n_splits=n_splits)\n",
    "    avg_mse_validation = 0\n",
    "    avg_mse_train = 0\n",
    "    avg_accuracy_validation = 0\n",
    "    avg_accuracy_train = 0\n",
    "    model = LogisticRegression(solver='liblinear')\n",
    "    for train_indices, validation_indices in kf.split(training_set):\n",
    "        train_features = train_X[train_indices]\n",
    "        train_labels = np.array([int(l) for l in train_Y[train_indices]])\n",
    "        validation_features = train_X[validation_indices]\n",
    "        validation_labels = np.array([int(l) for l in train_Y[validation_indices]])\n",
    "        model.fit(train_features, train_labels)\n",
    "        validation_prediction = model.predict(validation_features)\n",
    "        train_prediction = model.predict(train_features)\n",
    "        mse_validation = mean_squared_error(validation_labels, validation_prediction)\n",
    "        mse_train = mean_squared_error(train_labels, train_prediction)\n",
    "        accuracy_validation = accuracy_score(validation_labels, validation_prediction)\n",
    "        accuracy_train = accuracy_score(train_labels, train_prediction)\n",
    "        avg_mse_validation += mse_validation\n",
    "        avg_mse_train += mse_train\n",
    "        avg_accuracy_validation += accuracy_validation\n",
    "        avg_accuracy_train += accuracy_train\n",
    "    model.fit(train_X, train_Y)\n",
    "    test_prediction = model.predict(test_X)\n",
    "    test_prediction = np.array([int(l) for l in test_prediction])\n",
    "    test_Y = np.array([int(l) for l in test_Y])\n",
    "    test_mse = mean_squared_error(test_Y, test_prediction)\n",
    "    test_accuracy = accuracy_score(test_Y, test_prediction)\n",
    "    print(\"avg_mse_validation\", round(avg_mse_validation / 5, 6))\n",
    "    print(\"avg_mse_train\", round(avg_mse_train / 5, 6))\n",
    "    print(\"avg_accuracy_validation\", round(avg_accuracy_validation / 5, 6))\n",
    "    print(\"avg_accuracy_train\", round(avg_accuracy_train / 5, 6))\n",
    "    print(\"test_mse\", round(test_mse, 6))\n",
    "    print(\"test_accuracy\", round(test_accuracy, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of Unigram Experiment: \n",
      "avg_mse_validation 0.241887\n",
      "avg_mse_train 0.021712\n",
      "avg_accuracy_validation 0.758113\n",
      "avg_accuracy_train 0.978288\n",
      "test_mse 0.220625\n",
      "test_accuracy 0.779375\n"
     ]
    }
   ],
   "source": [
    "#Use uni-gram as the first method\n",
    "review = []\n",
    "for row in range(data.shape[0]):\n",
    "    review.append(data[row][0])\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(review)\n",
    "training_review = []\n",
    "for row in range(training_set.shape[0]):\n",
    "    training_review.append(training_set[row][0])\n",
    "test_review = []\n",
    "for row in range(test_set.shape[0]):\n",
    "    test_review.append(test_set[row][0])\n",
    "train_X = vectorizer.transform(training_review)\n",
    "train_Y = np.ravel(np.array(training_set.take([1], axis=1)))\n",
    "test_X = vectorizer.transform(test_review)\n",
    "test_Y = np.ravel(np.array(test_set.take([1], axis=1)))\n",
    "print(\"Result of Unigram Experiment: \")\n",
    "experiment(train_X=train_X, train_Y=train_Y, test_X=test_X, test_Y=test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of Unigram combined Stemming Experiment: \n",
      "avg_mse_validation 0.240895\n",
      "avg_mse_train 0.036912\n",
      "avg_accuracy_validation 0.759105\n",
      "avg_accuracy_train 0.963088\n",
      "test_mse 0.21875\n",
      "test_accuracy 0.78125\n"
     ]
    }
   ],
   "source": [
    "# Use uni-gram combined PorterStemmer as the second method\n",
    "porter = PorterStemmer()\n",
    "def stemming(text):\n",
    "    return ' '.join(porter.stem(word) for word in text.split())\n",
    "review = []\n",
    "for row in range(data.shape[0]):\n",
    "    review.append(stemming(data[row][0]))\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(review)\n",
    "training_review = []\n",
    "for row in range(training_set.shape[0]):\n",
    "    training_review.append(stemming(training_set[row][0]))\n",
    "test_review = []\n",
    "for row in range(test_set.shape[0]):\n",
    "    test_review.append(stemming(test_set[row][0]))\n",
    "train_X = vectorizer.transform(training_review)\n",
    "train_Y = np.ravel(np.array(training_set.take([1], axis=1)))\n",
    "test_X = vectorizer.transform(test_review)\n",
    "test_Y = np.ravel(np.array(test_set.take([1], axis=1)))\n",
    "print(\"Result of Unigram combined Stemming Experiment: \")\n",
    "experiment(train_X=train_X, train_Y=train_Y, test_X=test_X, test_Y=test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of Unigram combined Stopwords removing Experiment: \n",
      "avg_mse_validation 0.247075\n",
      "avg_mse_train 0.022291\n",
      "avg_accuracy_validation 0.752925\n",
      "avg_accuracy_train 0.977709\n",
      "test_mse 0.24125\n",
      "test_accuracy 0.75875\n"
     ]
    }
   ],
   "source": [
    "# Use uni-gram combined Stop word removing as the third method\n",
    "stop = stopwords.words('english')\n",
    "def removing(text):\n",
    "    return ' '.join(word for word in text.split() if word not in stop)\n",
    "review = []\n",
    "for row in range(data.shape[0]):\n",
    "    review.append(removing(data[row][0]))\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(review)\n",
    "training_review = []\n",
    "for row in range(training_set.shape[0]):\n",
    "    training_review.append(removing(training_set[row][0]))\n",
    "test_review = []\n",
    "for row in range(test_set.shape[0]):\n",
    "    test_review.append(removing(test_set[row][0]))\n",
    "train_X = vectorizer.transform(training_review)\n",
    "train_Y = np.ravel(np.array(training_set.take([1], axis=1)))\n",
    "test_X = vectorizer.transform(test_review)\n",
    "test_Y = np.ravel(np.array(test_set.take([1], axis=1)))\n",
    "print(\"Result of Unigram combined Stopwords removing Experiment: \")\n",
    "experiment(train_X=train_X, train_Y=train_Y, test_X=test_X, test_Y=test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of Bigram Experiment: \n",
      "avg_mse_validation 0.297616\n",
      "avg_mse_train 0.000469\n",
      "avg_accuracy_validation 0.702384\n",
      "avg_accuracy_train 0.999531\n",
      "test_mse 0.3025\n",
      "test_accuracy 0.6975\n"
     ]
    }
   ],
   "source": [
    "# Use bi-gram as the fourth method\n",
    "review = []\n",
    "for row in range(data.shape[0]):\n",
    "    review.append(data[row][0])\n",
    "vectorizer = CountVectorizer(ngram_range=(2,2))\n",
    "vectorizer.fit(review)\n",
    "training_review = []\n",
    "for row in range(training_set.shape[0]):\n",
    "    training_review.append(training_set[row][0])\n",
    "test_review = []\n",
    "for row in range(test_set.shape[0]):\n",
    "    test_review.append(test_set[row][0])\n",
    "train_X = vectorizer.transform(training_review)\n",
    "train_Y = np.ravel(np.array(training_set.take([1], axis=1)))\n",
    "test_X = vectorizer.transform(test_review)\n",
    "test_Y = np.ravel(np.array(test_set.take([1], axis=1)))\n",
    "print(\"Result of Bigram Experiment: \")\n",
    "experiment(train_X=train_X, train_Y=train_Y, test_X=test_X, test_Y=test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of Trigram Experiment: \n",
      "avg_mse_validation 0.392516\n",
      "avg_mse_train 0.004248\n",
      "avg_accuracy_validation 0.607484\n",
      "avg_accuracy_train 0.995752\n",
      "test_mse 0.383125\n",
      "test_accuracy 0.616875\n"
     ]
    }
   ],
   "source": [
    "# Trigram as the fiveth method\n",
    "review = []\n",
    "for row in range(data.shape[0]):\n",
    "    review.append(data[row][0])\n",
    "vectorizer = CountVectorizer(ngram_range=(3,3))\n",
    "vectorizer.fit(review)\n",
    "training_review = []\n",
    "for row in range(training_set.shape[0]):\n",
    "    training_review.append(training_set[row][0])\n",
    "test_review = []\n",
    "for row in range(test_set.shape[0]):\n",
    "    test_review.append(test_set[row][0])\n",
    "train_X = vectorizer.transform(training_review)\n",
    "train_Y = np.ravel(np.array(training_set.take([1], axis=1)))\n",
    "test_X = vectorizer.transform(test_review)\n",
    "test_Y = np.ravel(np.array(test_set.take([1], axis=1)))\n",
    "print(\"Result of Trigram Experiment: \")\n",
    "experiment(train_X=train_X, train_Y=train_Y, test_X=test_X, test_Y=test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of Unigram combined Lemmatization Experiment: \n",
      "avg_mse_validation 0.242659\n",
      "avg_mse_train 0.026374\n",
      "avg_accuracy_validation 0.757341\n",
      "avg_accuracy_train 0.973626\n",
      "test_mse 0.22625\n",
      "test_accuracy 0.77375\n"
     ]
    }
   ],
   "source": [
    "# Lemmatization as the sixth method\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatization(text):\n",
    "    return ' '.join(lemmatizer.lemmatize(word) for word in text.split())\n",
    "review = []\n",
    "for row in range(data.shape[0]):\n",
    "    review.append(lemmatization(data[row][0]))\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(review)\n",
    "training_review = []\n",
    "for row in range(training_set.shape[0]):\n",
    "    training_review.append(lemmatization(training_set[row][0]))\n",
    "test_review = []\n",
    "for row in range(test_set.shape[0]):\n",
    "    test_review.append(lemmatization(test_set[row][0]))\n",
    "train_X = vectorizer.transform(training_review)\n",
    "train_Y = np.ravel(np.array(training_set.take([1], axis=1)))\n",
    "test_X = vectorizer.transform(test_review)\n",
    "test_Y = np.ravel(np.array(test_set.take([1], axis=1)))\n",
    "print(\"Result of Unigram combined Lemmatization Experiment: \")\n",
    "experiment(train_X=train_X, train_Y=train_Y, test_X=test_X, test_Y=test_Y)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}